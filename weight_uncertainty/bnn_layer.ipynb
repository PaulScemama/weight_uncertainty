{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import linen as nn \n",
    "from flax.linen import initializers\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax.linen.module import compact\n",
    "from basic import logprior_fn, logvariational_fn, samplevariational_fn, sigmas_from_rhos\n",
    "from typing import (Any, Callable, Iterable, List, Optional, Sequence, Tuple,\n",
    "                    Union)\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "from jax import lax\n",
    "PRNGKey = Any\n",
    "Shape = Tuple[int, ...]\n",
    "Dtype = Any  # this could be a real type?\n",
    "Array = Any\n",
    "default_kernel_init = initializers.lecun_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNNLayer(nn.Module):\n",
    "\n",
    "    features: int\n",
    "    prior_pi: float\n",
    "    prior_var1: float\n",
    "    prior_var2: float\n",
    "    parameter_init: Callable = nn.initializers.lecun_normal()\n",
    "\n",
    "    @compact\n",
    "    def __call__(self, sampling_key: random.PRNGKey, inputs, n_samples: int):\n",
    "        # Variational Parameters\n",
    "        mus = self.param(\n",
    "            \"mus\", \n",
    "            self.parameter_init, \n",
    "            (jnp.shape(inputs)[-1] + 1, self.features))\n",
    "        rhos = self.param(\n",
    "            \"rhos\",\n",
    "            self.parameter_init,\n",
    "            (jnp.shape(inputs)[-1] + 1, self.features)\n",
    "        )\n",
    "\n",
    "        # Sample weights\n",
    "        weights = samplevariational_fn(\n",
    "            mus=mus,\n",
    "            rhos=rhos,\n",
    "            key=sampling_key,\n",
    "            n_samples=n_samples\n",
    "        )\n",
    "\n",
    "        # Augment inputs by adding a column of 1s so that\n",
    "        # biases don't need to be separately created.\n",
    "        column_of_ones = jnp.ones((jnp.shape(inputs)[0], 1))\n",
    "        inputs_augmented = jnp.concatenate((column_of_ones, inputs), axis=-1)\n",
    "        y = jnp.dot(inputs_augmented, weights)\n",
    "\n",
    "        # Compute terms for KL penalty\n",
    "        # Need to copy and stack due to multiple samples for weights.\n",
    "        stacked_mus = jnp.stack((mus,) * n_samples, axis=0)\n",
    "        stacked_rhos = jnp.stack((rhos,) * n_samples, axis=0)\n",
    "        log_variational_density = logvariational_fn(\n",
    "            weights=weights,\n",
    "            mus=stacked_mus,\n",
    "            rhos=stacked_rhos,\n",
    "        )\n",
    "        log_prior_density = logprior_fn(\n",
    "            weights=weights,\n",
    "            pi=self.prior_pi,\n",
    "            var1=self.prior_var1,\n",
    "            var2=self.prior_var2,\n",
    "        )\n",
    "        return y, log_variational_density, log_prior_density\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict({\n",
      "    params: {\n",
      "        mus: Array([[-0.02930064,  0.22184654, -0.8278271 ],\n",
      "               [ 0.843966  ,  0.0176126 ,  0.83982617],\n",
      "               [ 0.6925206 ,  0.13406326,  0.6939206 ],\n",
      "               [-0.6244742 , -0.9194189 ,  0.11918769],\n",
      "               [-0.21873963,  0.2695162 ,  0.4354371 ]], dtype=float32),\n",
      "        rhos: Array([[-0.2408339 ,  0.10038533,  0.661483  ],\n",
      "               [-1.001577  ,  0.18277498, -0.79746354],\n",
      "               [ 0.27618888, -0.06239573,  0.05086489],\n",
      "               [-0.27124298,  0.09979365, -0.6051223 ],\n",
      "               [ 0.24168347,  0.08925466, -0.7675577 ]], dtype=float32),\n",
      "    },\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([[[ 1.3309863 ,  2.221767  , -0.27026787],\n",
       "         [ 1.3309863 ,  2.221767  , -0.27026787]],\n",
       " \n",
       "        [[ 1.2240943 ,  2.5699005 , -0.3441275 ],\n",
       "         [ 1.2240943 ,  2.5699005 , -0.3441275 ]],\n",
       " \n",
       "        [[ 1.5596361 ,  2.3207808 ,  0.12029158],\n",
       "         [ 1.5596361 ,  2.3207808 ,  0.12029158]],\n",
       " \n",
       "        [[ 1.3289882 ,  1.7428572 , -0.19145672],\n",
       "         [ 1.3289882 ,  1.7428572 , -0.19145672]]], dtype=float32),\n",
       " Array([-2.1906397 , -2.877598  , -0.04729718, -1.1645566 , -0.6022583 ,\n",
       "        -1.1752043 , -1.1737965 , -1.2948349 , -1.0184361 , -1.7649992 ,\n",
       "        -5.522732  , -0.6626189 , -0.3937053 , -1.6940267 , -0.90627396,\n",
       "        -2.1906397 , -2.877598  , -0.04729718, -1.1645566 , -0.6022583 ,\n",
       "        -1.1752043 , -1.1737965 , -1.2948349 , -1.0184361 , -1.7649992 ,\n",
       "        -5.522732  , -0.6626189 , -0.3937053 , -1.6940267 , -0.90627396],      dtype=float32),\n",
       " Array([-2.36871   , -3.584829  , -2.1393044 , -1.6579031 , -1.5836654 ,\n",
       "        -1.6377769 , -0.23071143, -1.8581641 , -1.7490253 , -1.5744234 ,\n",
       "        -3.8987699 ,  0.66854286, -1.5762904 , -2.6876023 , -1.8685112 ,\n",
       "        -2.36871   , -3.584829  , -2.1393044 , -1.6579031 , -1.5836654 ,\n",
       "        -1.6377769 , -0.23071143, -1.8581641 , -1.7490253 , -1.5744234 ,\n",
       "        -3.8987699 ,  0.66854286, -1.5762904 , -2.6876023 , -1.8685112 ],      dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1, key2, key3 = random.split(random.PRNGKey(0), 3)\n",
    "\n",
    "x = random.uniform(key1, (4,4))\n",
    "model = BNNLayer(features=3, prior_pi=0.5, prior_var1=0.9, prior_var2=0.001)\n",
    "params = model.init(\n",
    "    rngs=key2, \n",
    "    sampling_key=key3,  \n",
    "    inputs=x, \n",
    "    n_samples=2)\n",
    "print(params)\n",
    "y = model.apply(params, key3, x, 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BNN(nn.Module):\n",
    "\n",
    "#     features: Sequence[int]\n",
    "#     prior_pi: float\n",
    "#     prior_var1: float\n",
    "#     prior_var2: float\n",
    "#     # parameter_init: Callable = nn.initializers.lecun_normal()\n",
    "\n",
    "#     def setup(self):\n",
    "#         # Right now same prior hyperparameters for each layers\n",
    "#         self.layers = [\n",
    "#             BNNLayer(\n",
    "#             features_, \n",
    "#             self.prior_pi, \n",
    "#             self.prior_var1, \n",
    "#             self.prior_var2\n",
    "#             ) for features_ in self.features\n",
    "#         ]\n",
    "\n",
    "#     def __call__(self, sampling_key: random.PRNGKey, inputs, n_samples: int):\n",
    "#         log_variational_densities = list()\n",
    "#         log_prior_densities = list()\n",
    "#         x = inputs\n",
    "#         for i, lyr in enumerate(self.layers):\n",
    "            \n",
    "#             x, log_variational_density, log_prior_density = lyr(sampling_key, x, n_samples)\n",
    "#             log_variational_densities.append(log_variational_density)\n",
    "#             log_prior_densities.append(log_prior_density)\n",
    "        \n",
    "#             if i != len(self.layers) - 1:\n",
    "#                 x = nn.relu(x)\n",
    "\n",
    "#         return x, log_variational_densities, log_prior_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
