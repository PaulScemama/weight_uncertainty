{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from basic import (log_variational_per_scalar, \n",
    "                         log_variational_per_vector, \n",
    "                         sample_variational_scalars, \n",
    "                         sample_variational_vectors,\n",
    "                         log_prior_per_scalar, \n",
    "                         log_prior_per_vector,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `log_variational_per_scalar`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn((25, 34)) \n",
    "mus = torch.randn((25, 34)) + 3\n",
    "rhos = torch.randn((25, 34))\n",
    "\n",
    "weight_matrix_flattened = weights.ravel()\n",
    "mus_flattened = mus.ravel()\n",
    "rhos_flattened = rhos.ravel()\n",
    "\n",
    "assert log_variational_per_scalar(weight_matrix_flattened, mus_flattened, rhos_flattened).shape[0], 25 * 34"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `log_variational_per_vector`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 instances of a 13-dimensional diagonal multivariate normal distribution\n",
    "weight_vectors = torch.randn((13, 5)) \n",
    "mu_vectors = torch.randn((13, 5)) + 3\n",
    "rho_vectors = torch.randn((13, 5))\n",
    "\n",
    "assert log_variational_per_vector(weight_vectors, mu_vectors, rho_vectors).shape[0] == 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesLinear:\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_features: int, \n",
    "            out_features: int, \n",
    "            prior_pi: float,\n",
    "            prior_sigma1: float,\n",
    "            prior_sigma2: float, \n",
    "            init_params: torch.Tensor = None\n",
    "            ):\n",
    "        \n",
    "        if init_params:\n",
    "            self.mu_vectors = init_params\n",
    "            self.rho_vectors = init_params\n",
    "        else:\n",
    "            self.mu_vectors = torch.empty(size=(in_features, out_features)).normal_()\n",
    "            self.rho_vectors = torch.empty(size=(in_features, out_features)).normal_()\n",
    "        \n",
    "        self.prior_pi = prior_pi\n",
    "        self.prior_sigma1 = prior_sigma1\n",
    "        self.prior_sigma2 = prior_sigma2\n",
    "\n",
    "    def __call__(self, x: torch.Tensor, n_samples: int = 1):\n",
    "\n",
    "        sampled_weight_vectors = sample_variational_vectors(\n",
    "            n_samples=n_samples,\n",
    "            mu_vectors=mu_vectors,\n",
    "            rho_vectors=rho_vectors\n",
    "        )\n",
    "\n",
    "        mean_linear_out = torch.stack(\n",
    "            [F.linear(x, sampled_weight_vectors[i].T) for i in range(n_samples)]\n",
    "        ).mean()\n",
    "\n",
    "        return mean_linear_out\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BayesLinear.__init__() missing 2 required positional arguments: 'prior_sigma1' and 'prior_sigma2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b \u001b[39m=\u001b[39m BayesLinear(\u001b[39m5\u001b[39;49m, \u001b[39m10\u001b[39;49m, {\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m}, )\n",
      "\u001b[0;31mTypeError\u001b[0m: BayesLinear.__init__() missing 2 required positional arguments: 'prior_sigma1' and 'prior_sigma2'"
     ]
    }
   ],
   "source": [
    "b = BayesLinear(5, 10, {1,2,3}, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_linear(\n",
    "            in_features, \n",
    "            out_features, \n",
    "            x, \n",
    "            prior_pi: float,\n",
    "            prior_sigma1: float,\n",
    "            prior_sigma2: float, \n",
    "            n_samples=1\n",
    "        ):\n",
    "\n",
    "    mu_vectors = torch.empty(size=(in_features, out_features)).normal_()\n",
    "    rho_vectors = torch.empty(size=(in_features, out_features)).normal_()\n",
    "\n",
    "    sampled_weight_vectors = sample_variational_vectors(\n",
    "        n_samples=n_samples,\n",
    "        mu_vectors=mu_vectors,\n",
    "        rho_vectors=rho_vectors\n",
    "        )\n",
    "    \n",
    "    mean_linear = torch.stack(\n",
    "        [F.linear(x, sampled_weight_vectors[i].T) for i in range(n_samples)]\n",
    "        ).mean()\n",
    "    \n",
    "    # mean_logprior = [logprior_fn(\n",
    "    #     sampled_weight_vectors[i], \n",
    "    #     pi=prior_pi, \n",
    "    #     sigma1=prior_sigma1, \n",
    "    #     sigma2=prior_sigma2) for i in range(n_samples)].mean()\n",
    "    \n",
    "    return mean_linear\n",
    "    \n",
    "    # bias_vector = torch.empty(size=(out_features,)).normal_()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1453)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 5), dtype=torch.float)\n",
    "bayes_linear(\n",
    "    5, \n",
    "    10, \n",
    "    x, \n",
    "    n_samples=1,\n",
    "    prior_pi = 0.5,\n",
    "    prior_sigma1=0.7,\n",
    "    prior_sigma2=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.0180, -9.5373, -8.2781], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_vector_samples = torch.randn(2, 3, 4)\n",
    "x = torch.randn((1,3))\n",
    "\n",
    "\n",
    "weight_vector_samples[0].shape\n",
    "\n",
    "log_prior_per_vector(weight_vector_samples[0], 0.5, 0.9, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-82.1949, -81.2742, -47.7652])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_variational_per_vector(weight_vector_samples[0], torch.randn((3,4)), torch.randn((3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3835)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([F.linear(x, weight_vector_samples[i].T) for i in range(2)]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.multivariate_normal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
